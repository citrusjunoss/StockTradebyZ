#!/usr/bin/env python3
"""
è‚¡ç¥¨æ•°æ®ç¼“å­˜ç®¡ç†å™¨ - ç®¡ç†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ã€å¸‚å€¼ã€PEç­‰æ•°æ®çš„ç¼“å­˜å’Œå®šæœŸæ›´æ–°
"""

import json
import logging
import os
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, List, Any

import pandas as pd
import baostock as bs

logger = logging.getLogger(__name__)

class StockDataCacheManager:
    """è‚¡ç¥¨æ•°æ®ç¼“å­˜ç®¡ç†å™¨ - ç®¡ç†å®Œæ•´çš„è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    
    def __init__(self, cache_file: str = "stock_info_cache.json"):
        self.cache_file = Path(cache_file)
        self.cache: Dict[str, Dict[str, Any]] = {}
        
        # ç¼“å­˜æœ‰æ•ˆæœŸ (å¤©)
        self.cache_validity_days = 15  # 15å¤©æ›´æ–°ä¸€æ¬¡
        
        # åŠ è½½ç°æœ‰ç¼“å­˜
        self.load_cache()
    
    def load_cache(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜"""
        try:
            if self.cache_file.exists():
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    self.cache = cache_data.get('stocks', {})
                logger.info(f"å·²åŠ è½½è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ï¼ŒåŒ…å« {len(self.cache)} åªè‚¡ç¥¨")
        except Exception as e:
            logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            self.cache = {}
    
    def save_cache(self) -> None:
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        try:
            cache_data = {
                'last_update': datetime.now().isoformat(),
                'data_source': 'baostock',
                'total_count': len(self.cache),
                'stocks': self.cache
            }
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²ä¿å­˜è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ï¼ŒåŒ…å« {len(self.cache)} åªè‚¡ç¥¨")
        except Exception as e:
            logger.error(f"ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def is_cache_valid(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        try:
            if not self.cache_file.exists():
                return False
                
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
                
            if 'last_update' not in cache_data:
                return False
                
            last_update = datetime.fromisoformat(cache_data['last_update'])
            return (datetime.now() - last_update).days < self.cache_validity_days
        except Exception as e:
            logger.warning(f"æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§å¤±è´¥: {e}")
            return False
    
    def update_stock_financial_data_only(self, code: str) -> Optional[Dict[str, Any]]:
        """15å¤©å‘¨æœŸå¢é‡æ›´æ–°ï¼šæ›´æ–°Kçº¿æ¥å£çš„æ‰€æœ‰æ•°æ®(ä»·æ ¼ã€æˆäº¤é‡ã€PEç­‰)ï¼ŒåŸºæœ¬ä¿¡æ¯(åç§°ã€è¡Œä¸š)ä»…åœ¨ç¼ºå¤±æ—¶æ›´æ–°"""
        try:
            # è½¬æ¢ä»£ç æ ¼å¼
            if code.startswith(('60', '68', '9')):
                bs_code = f"sh.{code.zfill(6)}"
            else:
                bs_code = f"sz.{code.zfill(6)}"
            
            # è·å–ç¼“å­˜ä¸­çš„ç°æœ‰æ•°æ®
            existing_data = self.cache.get(code, {})
            
            # åªæœ‰åœ¨åŸºæœ¬ä¿¡æ¯ç¼ºå¤±æ—¶æ‰è·å–
            need_basic_info = not existing_data.get('name') or existing_data.get('industry') == 'å¾…æ›´æ–°'
            
            if need_basic_info:
                # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
                rs = bs.query_stock_basic(code=bs_code)
                if rs.error_code != '0':
                    logger.error(f"âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs.error_code}, é”™è¯¯ä¿¡æ¯={rs.error_msg}")
                    return None
                
                basic_data = []
                while (rs.error_code == '0') & rs.next():
                    basic_data.append(rs.get_row_data())
                
                if not basic_data:
                    logger.error(f"âŒ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸ºç©º {bs_code}: æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
                    return None
                
                stock_info = dict(zip(rs.fields, basic_data[0]))
                
                # è·å–è¡Œä¸šä¿¡æ¯
                industry_info = existing_data.get('industry', 'æœªçŸ¥è¡Œä¸š')
                if industry_info in ['å¾…æ›´æ–°', 'æœªçŸ¥è¡Œä¸š', '']:
                    try:
                        rs_industry = bs.query_stock_industry(code=bs_code)
                        if rs_industry.error_code == '0':
                            industry_data = []
                            while (rs_industry.error_code == '0') & rs_industry.next():
                                industry_data.append(rs_industry.get_row_data())
                            
                            if industry_data:
                                industry_dict = dict(zip(rs_industry.fields, industry_data[0]))
                                industry_info = industry_dict.get('industry', 'æœªçŸ¥è¡Œä¸š')
                            else:
                                logger.warning(f"âš ï¸  è¡Œä¸šä¿¡æ¯ä¸ºç©º {bs_code}: æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
                        else:
                            logger.warning(f"âš ï¸  è·å–è¡Œä¸šä¿¡æ¯å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs_industry.error_code}, é”™è¯¯ä¿¡æ¯={rs_industry.error_msg}")
                    except Exception as e:
                        logger.warning(f"âš ï¸  è·å–è¡Œä¸šä¿¡æ¯å¼‚å¸¸ {bs_code}: {type(e).__name__}: {str(e)}")
            else:
                # ä½¿ç”¨ç°æœ‰çš„åŸºæœ¬ä¿¡æ¯
                stock_info = {
                    'code_name': existing_data.get('name', f'è‚¡ç¥¨{code}'),
                    'ipoDate': existing_data.get('list_date', ''),
                    'outDate': ''
                }
                industry_info = existing_data.get('industry', 'æœªçŸ¥è¡Œä¸š')
            
            # æ€»æ˜¯è·å–æœ€æ–°çš„Kçº¿æ•°æ®ï¼ˆä»·æ ¼ã€æˆäº¤é‡ã€ä¼°å€¼æŒ‡æ ‡ç­‰ï¼Œéƒ½æ¥è‡ªåŒä¸€ä¸ªAPIæ¥å£ï¼‰
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
            
            rs_kdata = bs.query_history_k_data_plus(
                bs_code,
                "date,code,open,high,low,close,preclose,volume,amount,pctChg,peTTM,pbMRQ,psTTM,pcfNcfTTM",
                start_date=start_date,
                end_date=end_date,
                frequency="d",
                adjustflag="3"
            )
            
            kdata_info = {}
            if rs_kdata.error_code == '0':
                kdata_list = []
                while (rs_kdata.error_code == '0') & rs_kdata.next():
                    kdata_list.append(rs_kdata.get_row_data())
                
                if kdata_list:
                    kdata_info = dict(zip(rs_kdata.fields, kdata_list[-1]))  # å–æœ€æ–°æ•°æ®
                else:
                    logger.warning(f"âš ï¸  Kçº¿æ•°æ®ä¸ºç©º {bs_code}: æœ€è¿‘7å¤©æ— äº¤æ˜“æ•°æ®")
            else:
                logger.warning(f"âš ï¸  è·å–Kçº¿æ•°æ®å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs_kdata.error_code}, é”™è¯¯ä¿¡æ¯={rs_kdata.error_msg}")
            
            # æ•´åˆä¿¡æ¯ - ä¿ç•™ç°æœ‰ä¿¡æ¯ï¼Œåªæ›´æ–°è´¢åŠ¡æ•°æ®
            result = {
                'code': code,
                'name': stock_info.get('code_name', existing_data.get('name', f'è‚¡ç¥¨{code}')),
                'industry': industry_info,
                'market': existing_data.get('market', self._get_market_by_code(code)),
                'list_date': stock_info.get('ipoDate', existing_data.get('list_date', '')),
                'list_status': stock_info.get('outDate', '') == '' and '1' or '0',
                'last_updated': datetime.now().isoformat(),
                'detailed_info_updated': True,
                'last_detailed_update': datetime.now().isoformat()
            }
            
            # æ›´æ–°åŒä¸€APIæ¥å£çš„æ‰€æœ‰æ•°æ®ï¼ˆä»·æ ¼ã€æˆäº¤ã€ä¼°å€¼æŒ‡æ ‡éƒ½æ¥è‡ªKçº¿æ•°æ®æ¥å£ï¼‰
            if kdata_info:
                result.update({
                    # ä»·æ ¼æ•°æ®ï¼ˆåŒä¸€æ¥å£ï¼‰
                    'close_price': float(kdata_info.get('close', 0)) if kdata_info.get('close') else 0,
                    'open_price': float(kdata_info.get('open', 0)) if kdata_info.get('open') else 0,
                    'high_price': float(kdata_info.get('high', 0)) if kdata_info.get('high') else 0,
                    'low_price': float(kdata_info.get('low', 0)) if kdata_info.get('low') else 0,
                    # æˆäº¤æ•°æ®ï¼ˆåŒä¸€æ¥å£ï¼‰
                    'volume': float(kdata_info.get('volume', 0)) if kdata_info.get('volume') else 0,
                    'amount': float(kdata_info.get('amount', 0)) if kdata_info.get('amount') else 0,
                    'pct_chg': float(kdata_info.get('pctChg', 0)) if kdata_info.get('pctChg') else 0,
                    # ä¼°å€¼æŒ‡æ ‡ï¼ˆåŒä¸€æ¥å£ï¼‰
                    'pe_ttm': float(kdata_info.get('peTTM', 0)) if kdata_info.get('peTTM') else None,
                    'pb_mrq': float(kdata_info.get('pbMRQ', 0)) if kdata_info.get('pbMRQ') else None,
                    'ps_ttm': float(kdata_info.get('psTTM', 0)) if kdata_info.get('psTTM') else None,
                    'pcf_ttm': float(kdata_info.get('pcfNcfTTM', 0)) if kdata_info.get('pcfNcfTTM') else None,
                })
                
                # ä¼°ç®—å¸‚å€¼ï¼ˆæ¯æ¬¡éƒ½æ›´æ–°ï¼‰
                close_price = result.get('close_price', 0)
                if close_price > 0:
                    if code.startswith(('000', '001', '002')):
                        estimated_shares = 8e8
                    elif code.startswith(('300', '301')):
                        estimated_shares = 4e8
                    elif code.startswith(('600', '601', '603', '605')):
                        estimated_shares = 15e8
                    elif code.startswith('688'):
                        estimated_shares = 6e8
                    else:
                        estimated_shares = 10e8
                    
                    result['market_cap'] = close_price * estimated_shares
                else:
                    result['market_cap'] = None
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¢é‡æ›´æ–°è‚¡ç¥¨{code}ä¿¡æ¯å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)}")
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {e}", exc_info=True)
            return None

    def get_stock_basic_info_from_baostock(self, code: str) -> Optional[Dict[str, Any]]:
        """ä»baostockè·å–å•åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯"""
        try:
            # è½¬æ¢ä»£ç æ ¼å¼
            if code.startswith(('60', '68', '9')):
                bs_code = f"sh.{code.zfill(6)}"
            else:
                bs_code = f"sz.{code.zfill(6)}"
            
            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            rs = bs.query_stock_basic(code=bs_code)
            if rs.error_code != '0':
                logger.error(f"âŒ è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs.error_code}, é”™è¯¯ä¿¡æ¯={rs.error_msg}")
                return None
            
            basic_data = []
            while (rs.error_code == '0') & rs.next():
                basic_data.append(rs.get_row_data())
            
            if not basic_data:
                logger.error(f"âŒ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸ºç©º {bs_code}: æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
                return None
            
            # å–ç¬¬ä¸€æ¡è®°å½•
            stock_info = dict(zip(rs.fields, basic_data[0]))
            
            # è·å–è¡Œä¸šä¿¡æ¯
            industry_info = "æœªçŸ¥è¡Œä¸š"
            try:
                rs_industry = bs.query_stock_industry(code=bs_code)
                if rs_industry.error_code == '0':
                    industry_data = []
                    while (rs_industry.error_code == '0') & rs_industry.next():
                        industry_data.append(rs_industry.get_row_data())
                    
                    if industry_data:
                        industry_dict = dict(zip(rs_industry.fields, industry_data[0]))
                        industry_info = industry_dict.get('industry', 'æœªçŸ¥è¡Œä¸š')
                    else:
                        logger.warning(f"âš ï¸  è¡Œä¸šä¿¡æ¯ä¸ºç©º {bs_code}: æŸ¥è¯¢è¿”å›ç©ºç»“æœ")
                else:
                    logger.warning(f"âš ï¸  è·å–è¡Œä¸šä¿¡æ¯å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs_industry.error_code}, é”™è¯¯ä¿¡æ¯={rs_industry.error_msg}")
            except Exception as e:
                logger.warning(f"âš ï¸  è·å–è¡Œä¸šä¿¡æ¯å¼‚å¸¸ {bs_code}: {type(e).__name__}: {str(e)}")
            
            # è·å–æœ€æ–°äº¤æ˜“æ•°æ®(åŒ…å«ä»·æ ¼ã€å¸‚å€¼ç­‰) - å°è¯•æœ€è¿‘å‡ å¤©çš„æ•°æ®
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
            
            rs_kdata = bs.query_history_k_data_plus(
                bs_code,
                "date,code,open,high,low,close,preclose,volume,amount,pctChg,peTTM,pbMRQ,psTTM,pcfNcfTTM",
                start_date=start_date,
                end_date=end_date,
                frequency="d",
                adjustflag="3"
            )
            
            kdata_info = {}
            if rs_kdata.error_code == '0':
                kdata_list = []
                while (rs_kdata.error_code == '0') & rs_kdata.next():
                    kdata_list.append(rs_kdata.get_row_data())
                
                if kdata_list:
                    kdata_info = dict(zip(rs_kdata.fields, kdata_list[-1]))  # å–æœ€æ–°æ•°æ®
                else:
                    logger.warning(f"âš ï¸  Kçº¿æ•°æ®ä¸ºç©º {bs_code}: æœ€è¿‘7å¤©æ— äº¤æ˜“æ•°æ®")
            else:
                logger.warning(f"âš ï¸  è·å–Kçº¿æ•°æ®å¤±è´¥ {bs_code}: é”™è¯¯ä»£ç ={rs_kdata.error_code}, é”™è¯¯ä¿¡æ¯={rs_kdata.error_msg}")
            
            # æ•´åˆä¿¡æ¯
            result = {
                'code': code,
                'name': stock_info.get('code_name', f'è‚¡ç¥¨{code}'),
                'industry': industry_info,
                'market': self._get_market_by_code(code),
                'list_date': stock_info.get('ipoDate', ''),
                'list_status': stock_info.get('outDate', '') == '' and '1' or '0',  # æ˜¯å¦æ­£å¸¸ä¸Šå¸‚
                'last_updated': datetime.now().isoformat()
            }
            
            # æ·»åŠ ä»·æ ¼å’Œä¼°å€¼æ•°æ®
            if kdata_info:
                result.update({
                    'close_price': float(kdata_info.get('close', 0)) if kdata_info.get('close') else 0,
                    'open_price': float(kdata_info.get('open', 0)) if kdata_info.get('open') else 0,
                    'high_price': float(kdata_info.get('high', 0)) if kdata_info.get('high') else 0,
                    'low_price': float(kdata_info.get('low', 0)) if kdata_info.get('low') else 0,
                    'volume': float(kdata_info.get('volume', 0)) if kdata_info.get('volume') else 0,
                    'amount': float(kdata_info.get('amount', 0)) if kdata_info.get('amount') else 0,
                    'pct_chg': float(kdata_info.get('pctChg', 0)) if kdata_info.get('pctChg') else 0,
                    'pe_ttm': float(kdata_info.get('peTTM', 0)) if kdata_info.get('peTTM') else None,
                    'pb_mrq': float(kdata_info.get('pbMRQ', 0)) if kdata_info.get('pbMRQ') else None,
                    'ps_ttm': float(kdata_info.get('psTTM', 0)) if kdata_info.get('psTTM') else None,
                    'pcf_ttm': float(kdata_info.get('pcfNcfTTM', 0)) if kdata_info.get('pcfNcfTTM') else None,
                })
                
                # ä¼°ç®—å¸‚å€¼
                close_price = result.get('close_price', 0)
                if close_price > 0:
                    # ä½¿ç”¨ç»éªŒå…¬å¼ä¼°ç®—æ€»è‚¡æœ¬
                    if code.startswith(('000', '001', '002')):
                        estimated_shares = 8e8  # 8äº¿è‚¡
                    elif code.startswith(('300', '301')):
                        estimated_shares = 4e8  # 4äº¿è‚¡
                    elif code.startswith(('600', '601', '603', '605')):
                        estimated_shares = 15e8  # 15äº¿è‚¡
                    elif code.startswith('688'):
                        estimated_shares = 6e8  # 6äº¿è‚¡
                    else:
                        estimated_shares = 10e8  # é»˜è®¤10äº¿è‚¡
                    
                    result['market_cap'] = close_price * estimated_shares
                else:
                    result['market_cap'] = None
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·å–è‚¡ç¥¨{code}ä¿¡æ¯å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)}")
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {e}", exc_info=True)
            return None
    
    def _get_market_by_code(self, code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­å¸‚åœº"""
        code = str(code).zfill(6)
        if code.startswith(('60', '68', '9')):
            return 'ä¸Šæµ·'
        elif code.startswith(('00', '30')):
            return 'æ·±åœ³'
        elif code.startswith('8'):
            return 'åŒ—äº¤æ‰€'
        else:
            return 'æœªçŸ¥'
    
    def initialize_stock_list(self) -> bool:
        """åˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨åˆ°ç¼“å­˜ä¸­ï¼ˆä¸åŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰"""
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨...")
            
            # ç™»å½•baostockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                raise RuntimeError(f"Baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            rs = bs.query_stock_basic()
            if rs.error_code != '0':
                bs.logout()
                raise RuntimeError(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {rs.error_msg}")
            
            stock_list = []
            while (rs.error_code == '0') & rs.next():
                stock_list.append(rs.get_row_data())
            
            bs.logout()
            
            if not stock_list:
                raise RuntimeError("æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
            
            # è¿‡æ»¤Aè‚¡å¹¶åˆå§‹åŒ–åŸºæœ¬ç»“æ„
            df_basic = pd.DataFrame(stock_list, columns=rs.fields)
            df_basic = df_basic[df_basic['code'].str.contains(r'^(sz|sh)\.(000|001|002|300|301|600|601|603|605|688)')]
            
            logger.info(f"æ‰¾åˆ°{len(df_basic)}åªAè‚¡ï¼Œå¼€å§‹åˆå§‹åŒ–ä»£ç åˆ—è¡¨")
            
            # åˆå§‹åŒ–æ‰€æœ‰è‚¡ç¥¨çš„åŸºæœ¬ç»“æ„
            for _, row in df_basic.iterrows():
                try:
                    code_with_market = row['code']
                    code = code_with_market.split('.')[1]
                    
                    # å¦‚æœç¼“å­˜ä¸­å·²æœ‰å®Œæ•´ä¿¡æ¯ï¼Œè·³è¿‡
                    if code in self.cache and 'close_price' in self.cache[code]:
                        continue
                    
                    # åˆå§‹åŒ–åŸºæœ¬ä¿¡æ¯ç»“æ„
                    self.cache[code] = {
                        'code': code,
                        'name': row.get('code_name', f'è‚¡ç¥¨{code}'),
                        'industry': 'å¾…æ›´æ–°',
                        'market': self._get_market_by_code(code),
                        'list_date': row.get('ipoDate', ''),
                        'list_status': row.get('outDate', '') == '' and '1' or '0',
                        'last_updated': datetime.now().isoformat(),
                        'detailed_info_updated': False  # æ ‡è®°æ˜¯å¦å·²æ›´æ–°è¯¦ç»†ä¿¡æ¯
                    }
                    
                except Exception as e:
                    logger.warning(f"åˆå§‹åŒ–è‚¡ç¥¨{row.get('code', 'unknown')}å¤±è´¥: {e}")
                    continue
            
            # ä¿å­˜ç¼“å­˜
            self.save_cache()
            logger.info(f"Aè‚¡ä»£ç åˆ—è¡¨åˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.cache)}åªè‚¡ç¥¨")
            return True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨å¤±è´¥: {e}")
            return False
    
    def update_stock_cache_financial_only_with_retry(self, delay_seconds: int = 10, max_consecutive_failures: int = 3) -> bool:
        """å¢é‡æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è´¢åŠ¡æ•°æ®ï¼Œ15å¤©é¢‘ç‡ï¼Œæ”¯æŒæ™ºèƒ½é€€é¿é‡è¯•"""
        # é€€é¿æ—¶é—´åºåˆ—ï¼š20s, 60s, 120s, 300s
        backoff_delays = [20, 60, 120, 300]
        consecutive_failures = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total_stocks': 0,
            'success_count': 0,
            'failure_count': 0,
            'skipped_count': 0,
            'start_time': datetime.now(),
            'end_time': None
        }
        
        try:
            # æ£€æŸ¥æ‰€æœ‰è‚¡ç¥¨
            all_codes = list(self.cache.keys())
            stats['total_stocks'] = len(all_codes)
            
            if not all_codes:
                logger.info("ç¼“å­˜ä¸ºç©ºï¼Œæ— è‚¡ç¥¨éœ€è¦æ›´æ–°")
                return True
            
            logger.info(f"å¼€å§‹15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°ï¼Œæ€»è‚¡ç¥¨æ•°ï¼š{len(all_codes)}")
            
            # ç™»å½•baostockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                raise RuntimeError(f"âŒ Baostockåˆå§‹ç™»å½•å¤±è´¥: é”™è¯¯ä»£ç ={lg.error_code}, é”™è¯¯ä¿¡æ¯={lg.error_msg}")
            
            for i, code in enumerate(all_codes):
                try:
                    logger.info(f"æ­£åœ¨æ›´æ–°è‚¡ç¥¨ {code} ({i+1}/{len(all_codes)}) [æˆåŠŸ:{stats['success_count']}, å¤±è´¥:{consecutive_failures}]")
                    
                    # ä½¿ç”¨å¢é‡æ›´æ–°æ–¹æ³•
                    stock_info = self.update_stock_financial_data_only(code)
                    if stock_info:
                        self.cache[code] = stock_info
                        stats['success_count'] += 1
                        consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                        
                        logger.info(f"âœ… æˆåŠŸæ›´æ–° {code}: {stock_info.get('name', 'æœªçŸ¥')} (PE:{stock_info.get('pe_ttm', 'N/A')}, å¸‚å€¼:{stock_info.get('market_cap', 0)/1e8:.1f}äº¿)")
                        
                        # æ¯100åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡ç¼“å­˜
                        if stats['success_count'] % 100 == 0:
                            self.save_cache()
                            logger.info(f"ğŸ“Š è¿›åº¦æ›´æ–° - å·²æˆåŠŸæ›´æ–°{stats['success_count']}åªè‚¡ç¥¨ï¼Œå·²ä¿å­˜ç¼“å­˜")
                    else:
                        consecutive_failures += 1
                        stats['failure_count'] += 1
                        logger.warning(f"âŒ è·å–è‚¡ç¥¨{code}è´¢åŠ¡æ•°æ®å¤±è´¥ (å¤±è´¥è®¡æ•°: {consecutive_failures}) - å¯èƒ½åŸå› : ç½‘ç»œé—®é¢˜ã€APIé™åˆ¶æˆ–æ•°æ®ä¸å­˜åœ¨")
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘é€€é¿æœºåˆ¶
                    if consecutive_failures >= max_consecutive_failures:
                        backoff_delay = backoff_delays[min(consecutive_failures - max_consecutive_failures, len(backoff_delays) - 1)]
                        logger.warning(f"ğŸ”„ è¿ç»­å¤±è´¥{consecutive_failures}æ¬¡ï¼Œè§¦å‘é€€é¿æœºåˆ¶ï¼Œæš‚åœ{backoff_delay}ç§’åç»§ç»­...")
                        time.sleep(backoff_delay)
                        consecutive_failures = 0  # é‡ç½®è®¡æ•°ï¼Œç»™ç³»ç»Ÿä¸€æ¬¡æœºä¼š
                        
                        # é‡æ–°ç™»å½•ï¼Œé˜²æ­¢ä¼šè¯è¶…æ—¶
                        try:
                            bs.logout()
                            lg = bs.login()
                            if lg.error_code != '0':
                                logger.error(f"âŒ é‡æ–°ç™»å½•å¤±è´¥: é”™è¯¯ä»£ç ={lg.error_code}, é”™è¯¯ä¿¡æ¯={lg.error_msg}")
                                break
                            logger.info("ğŸ”„ é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ›´æ–°...")
                        except Exception as e:
                            logger.error(f"âŒ é‡æ–°ç™»å½•å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)}")
                            break
                    else:
                        # æ­£å¸¸å»¶è¿Ÿç­‰å¾…
                        if i < len(all_codes) - 1:  # æœ€åä¸€åªè‚¡ç¥¨ä¸éœ€è¦ç­‰å¾…
                            logger.debug(f"ç­‰å¾…{delay_seconds}ç§’åå¤„ç†ä¸‹ä¸€åªè‚¡ç¥¨...")
                            time.sleep(delay_seconds)
                        
                except Exception as e:
                    consecutive_failures += 1
                    stats['failure_count'] += 1
                    logger.error(f"âŒ æ›´æ–°è‚¡ç¥¨{code}è´¢åŠ¡æ•°æ®å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)} (å¤±è´¥è®¡æ•°: {consecutive_failures})")
                    logger.debug(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {e}", exc_info=True)
                    continue
            
            bs.logout()
            
            # æœ€ç»ˆä¿å­˜ç¼“å­˜
            self.save_cache()
            stats['end_time'] = datetime.now()
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            duration = stats['end_time'] - stats['start_time']
            success_rate = (stats['success_count'] / stats['total_stocks'] * 100) if stats['total_stocks'] > 0 else 0
            
            logger.info("=" * 60)
            logger.info("ğŸ‰ 15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ")
            logger.info(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
            logger.info(f"   æ€»è‚¡ç¥¨æ•°: {stats['total_stocks']}")
            logger.info(f"   æˆåŠŸæ›´æ–°: {stats['success_count']} ({success_rate:.1f}%)")
            logger.info(f"   æ›´æ–°å¤±è´¥: {stats['failure_count']}")
            logger.info(f"   æ‰§è¡Œæ—¶é•¿: {duration}")
            logger.info(f"   å¹³å‡ç”¨æ—¶: {duration.total_seconds()/stats['total_stocks']:.2f}ç§’/è‚¡ç¥¨")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            stats['end_time'] = datetime.now()
            duration = stats['end_time'] - stats['start_time']
            
            logger.error("=" * 60)
            logger.error(f"âŒ 15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°å‘ç”Ÿä¸¥é‡å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            logger.error(f"ğŸ“Š ä¸­æ–­å‰ç»Ÿè®¡:")
            logger.error(f"   å·²å¤„ç†è‚¡ç¥¨: {stats['success_count'] + stats['failure_count']}/{stats['total_stocks']}")
            logger.error(f"   æˆåŠŸæ›´æ–°: {stats['success_count']}")
            logger.error(f"   æ›´æ–°å¤±è´¥: {stats['failure_count']}")
            logger.error(f"   æ‰§è¡Œæ—¶é•¿: {duration}")
            logger.error("=" * 60)
            logger.debug(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {e}", exc_info=True)
            
            try:
                bs.logout()
            except:
                pass
            return False

    def update_stock_cache_gradual_with_retry(self, delay_seconds: int = 10, max_consecutive_failures: int = 3) -> bool:
        """æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒæ™ºèƒ½é€€é¿é‡è¯•æœºåˆ¶"""
        # é€€é¿æ—¶é—´åºåˆ—ï¼š20s, 60s, 120s, 300s
        backoff_delays = [10, 15, 20, 30]
        consecutive_failures = 0
        
        try:
            # æ‰¾åˆ°éœ€è¦æ›´æ–°è¯¦ç»†ä¿¡æ¯çš„è‚¡ç¥¨
            pending_codes = []
            for code, info in self.cache.items():
                if not info.get('detailed_info_updated', False):
                    pending_codes.append(code)
            
            if not pending_codes:
                logger.info("æ‰€æœ‰è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å·²æ›´æ–°å®Œæˆ")
                return True
            
            logger.info(f"å¼€å§‹æ¸è¿›å¼æ›´æ–°ï¼Œå¾…æ›´æ–°è‚¡ç¥¨æ•°ï¼š{len(pending_codes)}")
            
            # ç™»å½•baostockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                raise RuntimeError(f"âŒ Baostockåˆå§‹ç™»å½•å¤±è´¥: é”™è¯¯ä»£ç ={lg.error_code}, é”™è¯¯ä¿¡æ¯={lg.error_msg}")
            
            updated_count = 0
            for i, code in enumerate(pending_codes):
                try:
                    logger.info(f"æ­£åœ¨æ›´æ–°è‚¡ç¥¨ {code} ({i+1}/{len(pending_codes)}) [è¿ç»­å¤±è´¥: {consecutive_failures}]")
                    
                    # è·å–è¯¦ç»†ä¿¡æ¯
                    stock_info = self.get_stock_basic_info_from_baostock(code)
                    if stock_info:
                        # ä¿ç•™åŸæœ‰çš„åŸºæœ¬ä¿¡æ¯ï¼Œæ›´æ–°è¯¦ç»†ä¿¡æ¯
                        original_info = self.cache[code].copy()
                        stock_info.update({
                            'detailed_info_updated': True,
                            'last_detailed_update': datetime.now().isoformat()
                        })
                        self.cache[code] = stock_info
                        updated_count += 1
                        consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                        
                        logger.info(f"âœ… æˆåŠŸæ›´æ–° {code}: {stock_info.get('name', 'æœªçŸ¥')}")
                        
                        # æ¯10åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡ç¼“å­˜
                        if updated_count % 10 == 0:
                            self.save_cache()
                            logger.info(f"å·²æ›´æ–°{updated_count}åªè‚¡ç¥¨ä¿¡æ¯ï¼Œå·²ä¿å­˜ç¼“å­˜")
                    else:
                        consecutive_failures += 1
                        logger.warning(f"âŒ è·å–è‚¡ç¥¨{code}è¯¦ç»†ä¿¡æ¯å¤±è´¥ (å¤±è´¥è®¡æ•°: {consecutive_failures}) - å¯èƒ½åŸå› : ç½‘ç»œé—®é¢˜ã€APIé™åˆ¶æˆ–æ•°æ®ä¸å­˜åœ¨")
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘é€€é¿æœºåˆ¶
                    if consecutive_failures >= max_consecutive_failures:
                        backoff_delay = backoff_delays[min(consecutive_failures - max_consecutive_failures, len(backoff_delays) - 1)]
                        logger.warning(f"ğŸ”„ è¿ç»­å¤±è´¥{consecutive_failures}æ¬¡ï¼Œè§¦å‘é€€é¿æœºåˆ¶ï¼Œæš‚åœ{backoff_delay}ç§’åç»§ç»­...")
                        time.sleep(backoff_delay)
                        consecutive_failures = 0  # é‡ç½®è®¡æ•°ï¼Œç»™ç³»ç»Ÿä¸€æ¬¡æœºä¼š
                        
                        # é‡æ–°ç™»å½•ï¼Œé˜²æ­¢ä¼šè¯è¶…æ—¶
                        try:
                            bs.logout()
                            lg = bs.login()
                            if lg.error_code != '0':
                                logger.error(f"âŒ é‡æ–°ç™»å½•å¤±è´¥: é”™è¯¯ä»£ç ={lg.error_code}, é”™è¯¯ä¿¡æ¯={lg.error_msg}")
                                break
                            logger.info("ğŸ”„ é‡æ–°ç™»å½•æˆåŠŸï¼Œç»§ç»­æ›´æ–°...")
                        except Exception as e:
                            logger.error(f"âŒ é‡æ–°ç™»å½•å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)}")
                            break
                    else:
                        # æ­£å¸¸å»¶è¿Ÿç­‰å¾…
                        if i < len(pending_codes) - 1:  # æœ€åä¸€åªè‚¡ç¥¨ä¸éœ€è¦ç­‰å¾…
                            logger.debug(f"ç­‰å¾…{delay_seconds}ç§’åå¤„ç†ä¸‹ä¸€åªè‚¡ç¥¨...")
                            time.sleep(delay_seconds)
                        
                except Exception as e:
                    consecutive_failures += 1
                    logger.error(f"âŒ æ›´æ–°è‚¡ç¥¨{code}è¯¦ç»†ä¿¡æ¯å‘ç”Ÿå¼‚å¸¸: {type(e).__name__}: {str(e)} (å¤±è´¥è®¡æ•°: {consecutive_failures})")
                    logger.debug(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {e}", exc_info=True)
                    continue
            
            bs.logout()
            
            # æœ€ç»ˆä¿å­˜ç¼“å­˜
            self.save_cache()
            logger.info(f"ğŸ‰ æ¸è¿›å¼æ›´æ–°å®Œæˆï¼ŒæˆåŠŸæ›´æ–°{updated_count}åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½é‡è¯•æ¸è¿›å¼æ›´æ–°å‘ç”Ÿä¸¥é‡å¼‚å¸¸: {type(e).__name__}: {str(e)}")
            logger.debug(f"è¯¦ç»†å¼‚å¸¸ä¿¡æ¯: {e}", exc_info=True)
            try:
                bs.logout()
            except:
                pass
            return False

    def update_stock_cache_gradual(self, delay_seconds: int = 1) -> bool:
        """æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼Œæ¯æ¬¡æ›´æ–°ä¸€åªè‚¡ç¥¨"""
        try:
            # æ‰¾åˆ°éœ€è¦æ›´æ–°è¯¦ç»†ä¿¡æ¯çš„è‚¡ç¥¨
            pending_codes = []
            for code, info in self.cache.items():
                if not info.get('detailed_info_updated', False):
                    pending_codes.append(code)
            
            if not pending_codes:
                logger.info("æ‰€æœ‰è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å·²æ›´æ–°å®Œæˆ")
                return True
            
            logger.info(f"å¼€å§‹æ¸è¿›å¼æ›´æ–°ï¼Œå¾…æ›´æ–°è‚¡ç¥¨æ•°ï¼š{len(pending_codes)}")
            
            # ç™»å½•baostockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                raise RuntimeError(f"Baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            
            updated_count = 0
            for i, code in enumerate(pending_codes):
                try:
                    logger.info(f"æ­£åœ¨æ›´æ–°è‚¡ç¥¨ {code} ({i+1}/{len(pending_codes)})")
                    
                    # è·å–è¯¦ç»†ä¿¡æ¯
                    stock_info = self.get_stock_basic_info_from_baostock(code)
                    if stock_info:
                        # ä¿ç•™åŸæœ‰çš„åŸºæœ¬ä¿¡æ¯ï¼Œæ›´æ–°è¯¦ç»†ä¿¡æ¯
                        original_info = self.cache[code].copy()
                        stock_info.update({
                            'detailed_info_updated': True,
                            'last_detailed_update': datetime.now().isoformat()
                        })
                        self.cache[code] = stock_info
                        updated_count += 1
                        
                        # æ¯10åªè‚¡ç¥¨ä¿å­˜ä¸€æ¬¡ç¼“å­˜
                        if updated_count % 10 == 0:
                            self.save_cache()
                            logger.info(f"å·²æ›´æ–°{updated_count}åªè‚¡ç¥¨ä¿¡æ¯ï¼Œå·²ä¿å­˜ç¼“å­˜")
                    else:
                        logger.warning(f"è·å–è‚¡ç¥¨{code}è¯¦ç»†ä¿¡æ¯å¤±è´¥")
                    
                    # å»¶è¿Ÿç­‰å¾…
                    if i < len(pending_codes) - 1:  # æœ€åä¸€åªè‚¡ç¥¨ä¸éœ€è¦ç­‰å¾…
                        logger.debug(f"ç­‰å¾…{delay_seconds}ç§’åå¤„ç†ä¸‹ä¸€åªè‚¡ç¥¨...")
                        time.sleep(delay_seconds)
                        
                except Exception as e:
                    logger.error(f"æ›´æ–°è‚¡ç¥¨{code}è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
                    continue
            
            bs.logout()
            
            # æœ€ç»ˆä¿å­˜ç¼“å­˜
            self.save_cache()
            logger.info(f"æ¸è¿›å¼æ›´æ–°å®Œæˆï¼ŒæˆåŠŸæ›´æ–°{updated_count}åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯")
            return True
            
        except Exception as e:
            logger.error(f"æ¸è¿›å¼æ›´æ–°å¤±è´¥: {e}")
            try:
                bs.logout()
            except:
                pass
            return False
    
    def update_stock_cache(self, force_update: bool = False, max_stocks: int = 500, gradual: bool = False, delay_seconds: int = 10, use_retry: bool = False, max_consecutive_failures: int = 3) -> bool:
        """æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ç¼“å­˜"""
        if not force_update and self.is_cache_valid():
            logger.info("è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œè·³è¿‡æ›´æ–°")
            return True
        
        # å¦‚æœå¯ç”¨æ¸è¿›æ›´æ–°æ¨¡å¼
        if gradual:
            # é¦–å…ˆç¡®ä¿å·²åˆå§‹åŒ–è‚¡ç¥¨ä»£ç åˆ—è¡¨
            if not self.cache:
                logger.info("ç¼“å­˜ä¸ºç©ºï¼Œå…ˆåˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨")
                if not self.initialize_stock_list():
                    return False
            
            # ç„¶åè¿›è¡Œæ¸è¿›å¼è¯¦ç»†ä¿¡æ¯æ›´æ–°
            if use_retry:
                return self.update_stock_cache_gradual_with_retry(delay_seconds, max_consecutive_failures)
            else:
                return self.update_stock_cache_gradual(delay_seconds)
        
        try:
            logger.info("å¼€å§‹æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜...")
            
            # ç™»å½•baostockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                raise RuntimeError(f"Baostockç™»å½•å¤±è´¥: {lg.error_msg}")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            rs = bs.query_stock_basic()
            if rs.error_code != '0':
                bs.logout()
                raise RuntimeError(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {rs.error_msg}")
            
            stock_list = []
            while (rs.error_code == '0') & rs.next():
                stock_list.append(rs.get_row_data())
            
            if not stock_list:
                bs.logout()
                raise RuntimeError("æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨")
            
            # è¿‡æ»¤Aè‚¡å¹¶å¤„ç†
            updated_count = 0
            df_basic = pd.DataFrame(stock_list, columns=rs.fields)
            df_basic = df_basic[df_basic['code'].str.contains(r'^(sz|sh)\.(000|001|002|300|301|600|601|603|605|688)')]
            
            # é™åˆ¶å¤„ç†æ•°é‡
            df_basic = df_basic.head(max_stocks)
            logger.info(f"å‡†å¤‡æ›´æ–°{len(df_basic)}åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯")
            
            for idx, row in df_basic.iterrows():
                try:
                    code_with_market = row['code']
                    code = code_with_market.split('.')[1]
                    
                    # è·å–è¯¦ç»†ä¿¡æ¯
                    stock_info = self.get_stock_basic_info_from_baostock(code)
                    if stock_info:
                        self.cache[code] = stock_info
                        updated_count += 1
                        
                        if updated_count % 50 == 0:
                            logger.info(f"å·²æ›´æ–°{updated_count}åªè‚¡ç¥¨ä¿¡æ¯")
                            # ä¸­é—´ä¿å­˜ï¼Œé¿å…æ•°æ®ä¸¢å¤±
                            self.save_cache()
                    
                    # æ·»åŠ å»¶æ—¶é¿å…é¢‘ç¹è¯·æ±‚
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.debug(f"æ›´æ–°è‚¡ç¥¨{row['code']}å¤±è´¥: {e}")
                    continue
            
            # ç™»å‡ºç³»ç»Ÿ
            bs.logout()
            
            # ä¿å­˜ç¼“å­˜
            self.save_cache()
            
            logger.info(f"è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜æ›´æ–°å®Œæˆï¼ŒæˆåŠŸæ›´æ–°{updated_count}åªè‚¡ç¥¨")
            return True
            
        except Exception as e:
            # ç¡®ä¿ç™»å‡º
            try:
                bs.logout()
            except:
                pass
            logger.error(f"æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def get_stock_info(self, code: str) -> Optional[Dict[str, Any]]:
        """è·å–å•åªè‚¡ç¥¨ä¿¡æ¯ï¼ˆä¼˜å…ˆä»ç¼“å­˜ï¼‰"""
        code = str(code).zfill(6)
        
        # å…ˆä»ç¼“å­˜è·å–
        if code in self.cache:
            return self.cache[code]
        
        # ç¼“å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»baostockè·å–
        try:
            lg = bs.login()
            if lg.error_code == '0':
                stock_info = self.get_stock_basic_info_from_baostock(code)
                bs.logout()
                
                if stock_info:
                    self.cache[code] = stock_info
                    return stock_info
        except Exception as e:
            logger.debug(f"ä»baostockè·å–è‚¡ç¥¨{code}ä¿¡æ¯å¤±è´¥: {e}")
            try:
                bs.logout()
            except:
                pass
        
        return None
    
    def get_stocks_by_market_cap(self, min_cap: float = None, max_cap: float = None) -> List[Dict[str, Any]]:
        """æ ¹æ®å¸‚å€¼ç­›é€‰è‚¡ç¥¨"""
        result = []
        
        for code, info in self.cache.items():
            market_cap = info.get('market_cap')
            if market_cap is None:
                continue
                
            # åº”ç”¨å¸‚å€¼ç­›é€‰
            if min_cap is not None and market_cap < min_cap:
                continue
            if max_cap is not None and market_cap > max_cap:
                continue
                
            result.append(info)
        
        # æŒ‰å¸‚å€¼æ’åº
        result.sort(key=lambda x: x.get('market_cap', 0), reverse=True)
        return result
    
    def get_cache_status(self) -> Dict:
        """è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        try:
            if not self.cache_file.exists():
                return {
                    'last_update': None,
                    'age_days': None,
                    'is_valid': False,
                    'data_source': None,
                    'total_count': 0
                }
            
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            last_update_str = cache_data.get('last_update')
            if last_update_str:
                last_update = datetime.fromisoformat(last_update_str)
                age_days = (datetime.now() - last_update).days
            else:
                last_update_str = None
                age_days = None
            
            return {
                'last_update': last_update_str,
                'age_days': age_days,
                'is_valid': age_days < self.cache_validity_days if age_days is not None else False,
                'data_source': cache_data.get('data_source', 'unknown'),
                'total_count': cache_data.get('total_count', len(self.cache))
            }
            
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            return {
                'last_update': None,
                'age_days': None,
                'is_valid': False,
                'data_source': None,
                'total_count': 0
            }
    
    def check_and_update_if_needed(self) -> bool:
        """æ£€æŸ¥å¹¶åœ¨éœ€è¦æ—¶æ›´æ–°"""
        if not self.is_cache_valid():
            logger.info("æ£€æµ‹åˆ°ç¼“å­˜è¿‡æœŸï¼Œå¼€å§‹æ›´æ–°...")
            return self.update_stock_cache(force_update=True)
        else:
            logger.info("ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œæ— éœ€æ›´æ–°")
            return True


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œå·¥å…·"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è‚¡ç¥¨æ•°æ®ç¼“å­˜ç®¡ç†å·¥å…·")
    parser.add_argument("--update", action="store_true", help="å¼ºåˆ¶æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜")
    parser.add_argument("--status", action="store_true", help="æ˜¾ç¤ºç¼“å­˜çŠ¶æ€")
    parser.add_argument("--check-update", action="store_true", help="æ£€æŸ¥å¹¶åœ¨éœ€è¦æ—¶æ›´æ–°ç¼“å­˜")
    parser.add_argument("--cache-file", default="stock_info_cache.json", help="ç¼“å­˜æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max-stocks", type=int, default=500, help="æœ€å¤§æ›´æ–°è‚¡ç¥¨æ•°é‡")
    parser.add_argument("--query-stock", type=str, help="æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨ä¿¡æ¯")
    parser.add_argument("--filter-mktcap", nargs=2, type=float, metavar=('MIN', 'MAX'), 
                        help="æŒ‰å¸‚å€¼ç­›é€‰è‚¡ç¥¨ (æœ€å°å€¼ æœ€å¤§å€¼)")
    parser.add_argument("--init", action="store_true", help="åˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨")
    parser.add_argument("--gradual", action="store_true", help="æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯")
    parser.add_argument("--gradual-retry", action="store_true", help="æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯(æ”¯æŒæ™ºèƒ½é‡è¯•)")
    parser.add_argument("--financial-update", action="store_true", help="15å¤©å‘¨æœŸKçº¿æ•°æ®æ›´æ–°(æ›´æ–°ä»·æ ¼ã€æˆäº¤é‡ã€PEç­‰åŒä¸€æ¥å£æ•°æ®ï¼ŒåŸºæœ¬ä¿¡æ¯ä»…åœ¨ç¼ºå¤±æ—¶æ›´æ–°)")
    parser.add_argument("--delay", type=int, default=10, help="æ¸è¿›æ›´æ–°æ—¶æ¯åªè‚¡ç¥¨é—´çš„å»¶è¿Ÿç§’æ•° (é»˜è®¤10ç§’)")
    parser.add_argument("--max-failures", type=int, default=3, help="è§¦å‘é€€é¿é‡è¯•çš„æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•° (é»˜è®¤3æ¬¡)")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )
    
    manager = StockDataCacheManager(cache_file=args.cache_file)
    
    if args.status:
        status = manager.get_cache_status()
        print("\n=== è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜çŠ¶æ€ ===")
        if status['last_update']:
            print(f"æœ€åæ›´æ–°: {status['last_update']}")
            print(f"æ•°æ®æº: {status['data_source']}")
            print(f"è‚¡ç¥¨æ€»æ•°: {status['total_count']}")
            print(f"ç¼“å­˜å¹´é¾„: {status['age_days']}å¤©")
            print(f"æ˜¯å¦æœ‰æ•ˆ: {'æ˜¯' if status['is_valid'] else 'å¦'}")
        else:
            print("æ— ç¼“å­˜æ•°æ®")
    
    elif args.init:
        print("å¼€å§‹åˆå§‹åŒ–Aè‚¡ä»£ç åˆ—è¡¨...")
        success = manager.initialize_stock_list()
        print("åˆå§‹åŒ–å®Œæˆ" if success else "åˆå§‹åŒ–å¤±è´¥")
    
    elif args.gradual:
        print(f"å¼€å§‹æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆå»¶è¿Ÿ{args.delay}ç§’ï¼‰...")
        success = manager.update_stock_cache_gradual(delay_seconds=args.delay)
        print("æ¸è¿›å¼æ›´æ–°å®Œæˆ" if success else "æ¸è¿›å¼æ›´æ–°å¤±è´¥")
    
    elif args.gradual_retry:
        print(f"å¼€å§‹æ™ºèƒ½é‡è¯•æ¸è¿›å¼æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆå»¶è¿Ÿ{args.delay}ç§’ï¼Œæœ€å¤§è¿ç»­å¤±è´¥{args.max_failures}æ¬¡ï¼‰...")
        success = manager.update_stock_cache_gradual_with_retry(
            delay_seconds=args.delay, 
            max_consecutive_failures=args.max_failures
        )
        print("æ™ºèƒ½é‡è¯•æ¸è¿›å¼æ›´æ–°å®Œæˆ" if success else "æ™ºèƒ½é‡è¯•æ¸è¿›å¼æ›´æ–°å¤±è´¥")
    
    elif args.financial_update:
        print(f"å¼€å§‹15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°ï¼ˆå»¶è¿Ÿ{args.delay}ç§’ï¼Œæœ€å¤§è¿ç»­å¤±è´¥{args.max_failures}æ¬¡ï¼‰...")
        success = manager.update_stock_cache_financial_only_with_retry(
            delay_seconds=args.delay, 
            max_consecutive_failures=args.max_failures
        )
        print("15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°å®Œæˆ" if success else "15å¤©å‘¨æœŸè´¢åŠ¡æ•°æ®æ›´æ–°å¤±è´¥")
    
    elif args.update:
        if args.gradual or args.gradual_retry:
            retry_text = "ï¼ˆæ”¯æŒæ™ºèƒ½é‡è¯•ï¼‰" if args.gradual_retry else ""
            print(f"å¼€å§‹æ¸è¿›å¼å¼ºåˆ¶æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ï¼ˆå»¶è¿Ÿ{args.delay}ç§’ï¼‰{retry_text}...")
            success = manager.update_stock_cache(
                force_update=True, 
                max_stocks=args.max_stocks, 
                gradual=True, 
                delay_seconds=args.delay,
                use_retry=args.gradual_retry,
                max_consecutive_failures=args.max_failures
            )
        else:
            print("å¼€å§‹å¼ºåˆ¶æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜...")
            success = manager.update_stock_cache(force_update=True, max_stocks=args.max_stocks)
        print("æ›´æ–°å®Œæˆ" if success else "æ›´æ–°å¤±è´¥")
    
    elif args.check_update:
        print("æ£€æŸ¥ç¼“å­˜çŠ¶æ€å¹¶åœ¨éœ€è¦æ—¶æ›´æ–°...")
        success = manager.check_and_update_if_needed()
        print("æ£€æŸ¥æ›´æ–°å®Œæˆ" if success else "æ£€æŸ¥æ›´æ–°å¤±è´¥")
    
    elif args.query_stock:
        print(f"æŸ¥è¯¢è‚¡ç¥¨ {args.query_stock} çš„ä¿¡æ¯...")
        stock_info = manager.get_stock_info(args.query_stock)
        if stock_info:
            print(f"è‚¡ç¥¨ä»£ç : {stock_info.get('code', 'N/A')}")
            print(f"è‚¡ç¥¨åç§°: {stock_info.get('name', 'N/A')}")
            print(f"æ‰€å±å¸‚åœº: {stock_info.get('market', 'N/A')}")
            print(f"æ‰€å±è¡Œä¸š: {stock_info.get('industry', 'N/A')}")
            print(f"æœ€æ–°ä»·æ ¼: {stock_info.get('close_price', 'N/A')}")
            print(f"å¸‚å€¼: {stock_info.get('market_cap', 'N/A')}")
            print(f"å¸‚ç›ˆç‡: {stock_info.get('pe_ttm', 'N/A')}")
            print(f"å¸‚å‡€ç‡: {stock_info.get('pb_mrq', 'N/A')}")
        else:
            print("æœªæ‰¾åˆ°è‚¡ç¥¨ä¿¡æ¯")
    
    elif args.filter_mktcap:
        min_cap, max_cap = args.filter_mktcap
        print(f"ç­›é€‰å¸‚å€¼åœ¨ {min_cap:.0f} - {max_cap:.0f} ä¹‹é—´çš„è‚¡ç¥¨...")
        stocks = manager.get_stocks_by_market_cap(min_cap, max_cap)
        print(f"æ‰¾åˆ° {len(stocks)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨:")
        for i, stock in enumerate(stocks[:20], 1):  # æ˜¾ç¤ºå‰20åª
            print(f"{i:2d}. {stock['code']} {stock['name']} "
                  f"å¸‚å€¼: {stock.get('market_cap', 0):.0f} "
                  f"PE: {stock.get('pe_ttm', 'N/A')}")
        if len(stocks) > 20:
            print(f"... è¿˜æœ‰ {len(stocks) - 20} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()